# Задание 1. Проектирование технологической архитектуры

### Определение стратегии масштабирования и отказоустойчивости.
При увеличении количества пользователей и запросов горизонтальное масштабирование эффективнее вертикального.
Предполагаем, что каждый сервис (core-app, client-info, ins-product-aggregator, ins-comp-settlement) в Kubernetes
будет иметь несколько реплик. Будем использовать HPA, чтобы автоматически менять количество подов в
зависимости от нагрузки.
Чтобы достичь требуемых показателей, нужно иметь не менее двух зон доступности. Если одна зона окажется
недоступной, трафик переключается на другую.
Для одинакового времени загрузки страниц в разных регионах развертываем веб-приложение и ключевые микросервисы в как
минимум двух регионах. Статический контент будем отдавать через CDN.

### Конфигурация Kubernetes
#### Конфигурация развертывания
Будем использовать независимые кластеры Kubernetes в двух зонах (AZ1 и AZ2). Впоследствии при недостаточности
количество зон можно увеличить.
Перед двумя кластерами ставим глобальный (или геораспределённый) балансировщик. Он направляет запросы пользователей
в ближайшую доступную зону. Если AZ1 перестаёт отвечать на health checks, весь трафик переходит на AZ2.
Чтобы один партнёр не «выедал» все ресурсы, в точке входа (API Gateway или Ingress) настраиваются лимиты RPS и throttling.
Внутри каждого кластера можно использовать Ingress-контроллер (например, NGINX Ingress), чтобы распределять
запросы между подами. В каждом кластере на уровне Deployment включается Horizontal Pod Autoscaler.

#### Фейловер-стратегия
Выбираем Active-Active стратегию. Оба кластера работают одновременно и принимают часть запросов. При этом они
синхронно или почти синхронно обмениваются данными через слой базы данных.
Подключаем Prometheus + Grafana в каждом кластере с общей системой алертинга. При падении кластера или резком скачке
метрик высылается уведомление по Slack/Telegram/email, что сокращает время реакции и помогает уложиться в 45 минут
на RTO.


#### Конфигурация базы данных
Будем использовать Primary-Standby (в одной из зон стоит Primary, во второй — Synchronous Standby) и внедрим
Point-in-Time Recovery (PITR), чтобы можно было откатиться к состоянию БД на нужный момент с точностью до 15 минут.
Бэкапы (WAL-логи и снапшоты) будем хранить в отдельном объектном хранилище (например, S3-совместимом) для надёжности.
Текущий общий объём данных (50 ГБ) - относительно небольшой, и шардировать немедленно не обязательно.
При росте данных можно планировать разделение по регионам или логическое партиционирование (например, по ID клиента).
Но сейчас, скорее всего, хватит реплицированного кластера.


[Ссылка на диаграмму](https://drive.google.com/file/d/1-mgIV5qHbLU1l-ir2-es3D6LsB7uSUEj/view?usp=sharing)